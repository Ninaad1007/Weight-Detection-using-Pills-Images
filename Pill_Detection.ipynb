{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninaad1007/Weight-Detection-using-Pills-Images/blob/main/Pill_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input Data**"
      ],
      "metadata": {
        "id": "qLlyP9nqL4ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B0x0RqcZNPY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990db510-8f8b-407c-a773-58442fc890c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.listdir('https://drive.google.com/drive/folders/1CNRIVuKOHhzV6nLJ6_wAxciBMz8S5XxZ')"
      ],
      "metadata": {
        "id": "rcbaRFJ9QJ4_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4w4DV7oV8sqH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "data = []\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    img = cv2.imread(os.path.join(path, filename))\n",
        "    height, width, channels = img.shape\n",
        "    size = os.path.getsize(os.path.join(path, filename))\n",
        "    ty = img.dtype\n",
        "    data.append([filename, size, width, height, channels,ty])\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data, columns=['filename', 'size', 'width', 'height', 'channels','ty'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YEIWM9JIos97",
        "outputId": "1ad40c98-bc77-46aa-956a-6a748815f085"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  filename   size  width  height  channels     ty\n",
              "0  IMG-20230327-WA0058.jpg  15269   1392     928         3  uint8\n",
              "1  IMG-20230327-WA0057.jpg  15122   1392     928         3  uint8\n",
              "2  IMG-20230327-WA0056.jpg  15062   1392     928         3  uint8\n",
              "3  IMG-20230327-WA0055.jpg  15024   1392     928         3  uint8\n",
              "4  IMG-20230327-WA0054.jpg  15161   1392     928         3  uint8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40dfce72-b89f-44c8-a264-b9cbd0f9307e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>size</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>channels</th>\n",
              "      <th>ty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG-20230327-WA0058.jpg</td>\n",
              "      <td>15269</td>\n",
              "      <td>1392</td>\n",
              "      <td>928</td>\n",
              "      <td>3</td>\n",
              "      <td>uint8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG-20230327-WA0057.jpg</td>\n",
              "      <td>15122</td>\n",
              "      <td>1392</td>\n",
              "      <td>928</td>\n",
              "      <td>3</td>\n",
              "      <td>uint8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG-20230327-WA0056.jpg</td>\n",
              "      <td>15062</td>\n",
              "      <td>1392</td>\n",
              "      <td>928</td>\n",
              "      <td>3</td>\n",
              "      <td>uint8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG-20230327-WA0055.jpg</td>\n",
              "      <td>15024</td>\n",
              "      <td>1392</td>\n",
              "      <td>928</td>\n",
              "      <td>3</td>\n",
              "      <td>uint8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG-20230327-WA0054.jpg</td>\n",
              "      <td>15161</td>\n",
              "      <td>1392</td>\n",
              "      <td>928</td>\n",
              "      <td>3</td>\n",
              "      <td>uint8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40dfce72-b89f-44c8-a264-b9cbd0f9307e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40dfce72-b89f-44c8-a264-b9cbd0f9307e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40dfce72-b89f-44c8-a264-b9cbd0f9307e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your image directory\n",
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "\n",
        "# Create empty lists to store your original and filtered images\n",
        "org = []\n",
        "images = []\n",
        "\n",
        "# Loop through all the files in your image directory\n",
        "for filename in os.listdir(path):\n",
        "    # Load each image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path,filename))\n",
        "    #img = cv2.resize(img, (10000, 10000))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply a Gaussian blur with a 5x5 kernel\n",
        "    blur = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "    # Define a sharpening kernel\n",
        "    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened = cv2.filter2D(blur, -1, kernel)\n",
        "\n",
        "    # Add the original and sharpened images to their respective lists\n",
        "    org.append(gray)\n",
        "    images.append(sharpened)"
      ],
      "metadata": {
        "id": "jowxyCbzk73q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Convert the lists of original and sharpened images to numpy arrays\n",
        "org = np.array(org)\n",
        "images = np.array(images)\n",
        "\n",
        "# Define the image data generator with desired augmentation settings\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Reshape the sharpened images to match the input shape of the data generator\n",
        "images_reshaped = images.reshape(images.shape + (1,))\n",
        "\n",
        "# Generate augmented images using the data generator\n",
        "augmented_images_generator = datagen.flow(images_reshaped, batch_size=1, shuffle=False)\n",
        "\n",
        "# Iterate through the augmented images generator and store the augmented images\n",
        "augmented_images = []\n",
        "for i in range(images.shape[0]):\n",
        "    augmented_image = next(augmented_images_generator)[0, :, :, 0]\n",
        "    augmented_images.append(augmented_image)\n",
        "\n",
        "# Convert the list of augmented images to a numpy array\n",
        "augmented_images = np.array(augmented_images)\n",
        "\n",
        "# Merge the sharpened images and augmented images into a single array\n",
        "merged_images = np.concatenate((images, augmented_images), axis=0)\n",
        "\n",
        "# Print the size of the merged images array\n",
        "print(\"Shape of merged images:\", merged_images.shape)\n",
        "\n",
        "# Display a sample image from the merged images\n",
        "sample_image = merged_images[0]  # Change the index as needed\n",
        "cv2_imshow(sample_image)"
      ],
      "metadata": {
        "id": "dphQ8SVqTyTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOO MUCH TIME, NOT OPTIMIZED\n",
        "from tqdm import tqdm\n",
        "# Define the path to your image directory\n",
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "\n",
        "# Create empty lists to store your original and filtered images\n",
        "org = []\n",
        "images = []\n",
        "segmented_images = []\n",
        "\n",
        "# Loop through all the files in your image directory\n",
        "for filename in tqdm(os.listdir(path)):\n",
        "    # Load each image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path,filename))\n",
        "    #img = cv2.resize(img, (10000, 10000))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Median filter\n",
        "    #blur = cv2.medianBlur(gray, 5)\n",
        "    # Apply an adaptive median filter with a 5x5 kernel\n",
        "    #adaptive = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    # Apply a Gaussian blur with a 5x5 kernel\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Apply Bilateral filter\n",
        "    #bilateral = cv2.bilateralFilter(gray, 9, 75, 75)\n",
        "    # Define a sharpening kernel\n",
        "    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened = cv2.filter2D(blur, -1, kernel)\n",
        "    # Perform img segmentation using grabCut\n",
        "    mask = np.zeros(sharpened.shape[:2], np.uint8)\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "    rect = (10, 10, sharpened.shape[1]-40, sharpened.shape[0]-40)\n",
        "    cv2.grabCut(sharpened, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "    segmented = sharpened * mask2[:, :, np.newaxis]\n",
        "\n",
        "    # Add the original, sharpened, and segmented images to their respective lists\n",
        "    org.append(gray)\n",
        "    images.append(sharpened)\n",
        "    segmented_images.append(segmented)"
      ],
      "metadata": {
        "id": "FizCA4vAoAgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9799926b-d307-49fb-d98a-1ee1174dcfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44/44 [00:05<00:00,  8.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave\n",
        "from tqdm import tqdm\n",
        "# Define the path to your image directory\n",
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "\n",
        "# Create empty lists to store your original and filtered images\n",
        "org = []\n",
        "images = []\n",
        "segmented_images = []\n",
        "\n",
        "# Loop through all the files in your image directory\n",
        "for filename in tqdm(os.listdir(path)):\n",
        "    # Load each image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path,filename))\n",
        "    #img = cv2.resize(img, (10000, 10000))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Median filter\n",
        "    #blur = cv2.medianBlur(gray, 5)\n",
        "    # Apply an adaptive median filter with a 5x5 kernel\n",
        "    #adaptive = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    # Apply a Gaussian blur with a 5x5 kernel\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Apply Bilateral filter\n",
        "    #bilateral = cv2.bilateralFilter(gray, 9, 75, 75)\n",
        "    # Define a sharpening kernel\n",
        "    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened = cv2.filter2D(blur, -1, kernel)\n",
        "\n",
        "    # Perform watershed segmentation on the sharpened image\n",
        "    thresh = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "    ret, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers+1\n",
        "    markers[unknown==255] = 0\n",
        "    markers = cv2.watershed(img,markers)\n",
        "    img[markers == -1] = [255,0,0]\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[markers != 1] = 255\n",
        "    segmented = cv2.bitwise_and(sharpened, sharpened, mask=mask)\n",
        "\n",
        "    # Add the original, sharpened, and segmented images to their respective lists\n",
        "    org.append(gray)\n",
        "    images.append(sharpened)\n",
        "    segmented_images.append(segmented)\n",
        "\n",
        "    # Add the original, sharpened, and segmented images to their respective lists\n",
        "    org.append(gray)\n",
        "    images.append(sharpened)\n",
        "    segmented_images.append(segmented)"
      ],
      "metadata": {
        "id": "HmUzjyd2ElJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INVERTED ONE #RUNNING ONE\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your image directory\n",
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "\n",
        "# Create empty lists to store your original and filtered images\n",
        "org = []\n",
        "images = []\n",
        "segmented_images = []\n",
        "\n",
        "# Loop through all the files in your image directory\n",
        "for filename in tqdm(os.listdir(path)):\n",
        "    # Load each image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path,filename))\n",
        "\n",
        "    # Invert the colors of the image\n",
        "    inverted_img = cv2.bitwise_not(img)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(inverted_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply a Gaussian blur with a 5x5 kernel\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Define a sharpening kernel\n",
        "    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened = cv2.filter2D(blur, -1, kernel)\n",
        "\n",
        "    # Perform watershed segmentation on the sharpened image\n",
        "    thresh = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "    ret, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers+1\n",
        "    markers[unknown==255] = 0\n",
        "    markers = cv2.watershed(inverted_img,markers)\n",
        "    inverted_img[markers == -1] = [255,0,0]\n",
        "    mask = np.zeros(inverted_img.shape[:2], np.uint8)\n",
        "    mask[markers != 1] = 255\n",
        "    segmented_inverted = cv2.bitwise_and(sharpened, sharpened, mask=mask)\n",
        "\n",
        "    # Invert the colors of the segmented image back\n",
        "    segmented = cv2.bitwise_not(segmented_inverted)\n",
        "\n",
        "    # Add the original, sharpened, and segmented images to their respective lists\n",
        "    org.append(img)\n",
        "    images.append(sharpened)\n",
        "    segmented_images.append(segmented)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z141JzqrtVg7",
        "outputId": "27539a59-d19d-4036-f555-155ced596b4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44/44 [00:03<00:00, 14.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WORKING OKAY\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the path to your image directory\n",
        "path = 'drive/MyDrive/Pills dataset/pills detection project'\n",
        "\n",
        "# Create empty lists to store your original and filtered images\n",
        "org = []\n",
        "images = []\n",
        "segmented_images = []\n",
        "\n",
        "# Loop through all the files in your image directory\n",
        "for filename in tqdm(os.listdir(path)):\n",
        "    # Load each image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path,filename))\n",
        "    #img = cv2.resize(img, (10000, 10000))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Median filter\n",
        "    #blur = cv2.medianBlur(gray, 5)\n",
        "    # Apply an adaptive median filter with a 5x5 kernel\n",
        "    #adaptive = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    # Apply a Gaussian blur with a 5x5 kernel\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Apply Bilateral filter\n",
        "    #bilateral = cv2.bilateralFilter(gray, 9, 75, 75)\n",
        "    # Define a sharpening kernel\n",
        "    kernl = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened = cv2.filter2D(blur, -1, kernl)\n",
        "    # Threshold the image to segment the white part of the pill\n",
        "    _, thresh = cv2.threshold(sharpened, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Perform morphological operations to remove noise and fill in small gaps\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Perform image segmentation on the sharpened and filtered image\n",
        "    segmented = cv2.bitwise_and(img, img, mask=closing)\n",
        "\n",
        "    # Add the original and segmented images to their respective lists\n",
        "    org.append(gray)\n",
        "    images.append(sharpened)\n",
        "    segmented_images.append(segmented)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jGHEJ4bnSqH",
        "outputId": "311fd2b8-a235-43e6-cde2-af1386741fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44/44 [00:00<00:00, 49.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define the filename for the pickle file\n",
        "filename = 'segmented_images.pkl'\n",
        "\n",
        "# Store the list of segmented images in the pickle file\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(segmented_images, file)\n",
        "\n",
        "# Load the pickled list of segmented images\n",
        "with open(filename, 'rb') as file:\n",
        "    segmented_images = pickle.load(file)"
      ],
      "metadata": {
        "id": "h49zuI-QcH7w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average PSNR: 41.98108975013711 {gaussian blur}, edge sharpening changes - 48.7\n",
        "Average PSNR: 40.09666528096421 {median blur}\n",
        "Average PSNR: 40.332116018048644 {bilateral filter}\n",
        "adaptive median\n",
        "Average accuracy: 0.1890158317404753\n",
        "Average PSNR: 1.4922491009300627\n",
        "Average MSE: 126.70013779830674\n",
        "Average ASNR: -21.02708945844398\n"
      ],
      "metadata": {
        "id": "dN0nmmIQRRNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_list = []\n",
        "psnr_list = []\n",
        "mse_list = []\n",
        "asnr_list = []\n",
        "\n",
        "for i in range(len(org)):\n",
        "    accuracy = cv2.norm(org[i], images[i], cv2.NORM_L2) / (org[i].shape[0] * org[i].shape[1])\n",
        "    accuracy_list.append(accuracy)\n",
        "    # Calculate PSNR\n",
        "    psnr = cv2.PSNR(org[i], images[i])\n",
        "    psnr_list.append(psnr)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = np.square(np.subtract(org[i], images[i])).mean()\n",
        "    mse_list.append(mse)\n",
        "\n",
        "    # Calculate ASNR\n",
        "    asnr = 10 * np.log10(np.mean(np.square(images[i])) / mse)\n",
        "    asnr_list.append(asnr)\n",
        "\n",
        "# Calculate PSNR, MSE, and ASNR\n",
        "average_psnr = sum(psnr_list) / len(psnr_list)\n",
        "average_mse = sum(mse_list) / len(mse_list)\n",
        "average_asnr = sum(asnr_list) / len(asnr_list)\n",
        "\n",
        "print(\"Average PSNR:\", average_psnr)\n",
        "print(\"Average MSE:\", average_mse)\n",
        "print(\"Average ASNR:\", average_asnr)"
      ],
      "metadata": {
        "id": "isPFZUQsZQ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img1 = segmented_images[1]\n",
        "img3 = images[1]\n",
        "img2 = org[1]\n",
        "# Display your image\n",
        "cv2_imshow(img1)\n",
        "cv2_imshow(img2)\n",
        "cv2_imshow(img3)\n",
        "# Wait for a key press\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# Close all windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lAOywDjPRB-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "filename = 'segmented_images.pkl'\n",
        "# Load the pickled list of segmented images\n",
        "with open(filename, 'rb') as file:\n",
        "    segmented_images = pickle.load(file)\n",
        "\n",
        "# Create an empty list to store augmented images\n",
        "augmented_images = []\n",
        "\n",
        "# Define the image data generator with desired augmentation settings\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Loop through all the segmented images\n",
        "for img in segmented_images:\n",
        "    # Reshape the image to match the input shape of the data generator\n",
        "    img = img.reshape((1,) + img.shape + (3,))  # Assuming segmented images are RGB\n",
        "\n",
        "    # Generate augmented images using the data generator\n",
        "    augmented_imgs = datagen.flow(img, batch_size=1)\n",
        "\n",
        "    # Iterate through the augmented images and store them in the list\n",
        "    for batch in augmented_imgs:\n",
        "        augmented_images.append(batch[0])\n",
        "        break  # Exit the loop after one iteration\n",
        "\n",
        "# Convert the list of augmented images to a numpy array\n",
        "augmented_images = np.array(augmented_images)\n",
        "\n",
        "# Print the shape of the augmented images array\n",
        "print(augmented_images.shape)"
      ],
      "metadata": {
        "id": "K1oD0M76h4Kd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ba2651bb-a0e2-490d-8581-46f76ad5edcb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f82195edc7f7>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegmented_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Reshape the image to match the input shape of the data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming segmented images are RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Generate augmented images using the data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1291776 into shape (1,928,1392,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define the filename for the pickle file\n",
        "filename = 'augmented_images.pkl'\n",
        "\n",
        "# Store the list of augmented images in the pickle file\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(augmented_images, file)\n",
        "\n",
        "# Print a message to confirm that the images are stored\n",
        "print(\"Augmented images saved in pickle file:\", filename)"
      ],
      "metadata": {
        "id": "BiVb6m79h5uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Define the filename for the pickle file\n",
        "filename = 'segmented_images.pkl'\n",
        "\n",
        "# Load the pickled list of segmented images\n",
        "with open(filename, 'rb') as file:\n",
        "    segmented_images = pickle.load(file)\n",
        "\n",
        "# Define the transform to apply to each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert image to RGB\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the pre-trained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = torch.nn.Identity()  # Remove the last fully connected layer\n",
        "model.eval()\n",
        "\n",
        "# Create an empty list to store the extracted features\n",
        "features = []\n",
        "\n",
        "# Loop through each segmented image\n",
        "for segmented_img in segmented_images:\n",
        "    # Convert the segmented image to PIL Image\n",
        "    img = Image.fromarray(segmented_img)\n",
        "\n",
        "    # Apply the transform to the image\n",
        "    img = transform(img)\n",
        "\n",
        "    # Move the image to the GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    img = img.to(device)\n",
        "\n",
        "    # Extract features from the image using the pre-trained model\n",
        "    with torch.no_grad():\n",
        "        features.append(model(img.unsqueeze(0)).squeeze().cpu().numpy())\n",
        "\n",
        "# Convert the list of extracted features to a pandas DataFrame\n",
        "df_features = pd.DataFrame(features)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_features)"
      ],
      "metadata": {
        "id": "FdLHoXYGV7af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6becf76-66fd-4491-e970-b178acb25fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2         3         4         5         6     \\\n",
            "0   0.672046  0.303708  0.056931  0.364897  0.261658  0.281031  0.216723   \n",
            "1   0.586179  0.293391  0.313102  0.252553  0.264107  0.154309  0.251515   \n",
            "2   0.203774  0.321128  0.009448  0.245554  0.294497  0.241310  0.252197   \n",
            "3   0.575792  0.620330  0.024539  0.124652  0.174120  0.813392  0.252264   \n",
            "4   0.239206  0.675596  0.009298  0.293029  0.234406  1.172196  0.263070   \n",
            "5   0.199104  0.597080  0.070536  0.299139  0.208550  0.518677  0.213187   \n",
            "6   0.197702  0.163493  0.009385  0.344603  0.176447  0.436660  0.990725   \n",
            "7   0.450585  0.714182  0.188200  0.307650  0.669321  0.677302  0.313406   \n",
            "8   0.008599  0.463540  0.009926  0.270548  0.149324  1.144218  0.273179   \n",
            "9   0.353491  0.943045  0.078180  0.367949  0.653004  0.837545  0.427270   \n",
            "10  0.195200  0.864214  0.032156  0.104386  0.195648  0.762620  0.296075   \n",
            "11  0.110286  0.546925  0.009585  0.230123  0.180326  0.557117  0.688570   \n",
            "12  0.115095  0.401100  0.009597  0.261510  0.572062  0.294904  0.883058   \n",
            "13  0.461483  0.282670  0.040531  0.195598  0.132777  0.077618  0.503954   \n",
            "14  0.420913  0.138432  0.024419  0.331130  0.169292  0.071538  0.550387   \n",
            "15  0.182808  0.785660  0.012515  0.160605  0.249254  0.530405  0.296330   \n",
            "16  0.686555  0.113911  0.031434  0.550805  0.386946  0.056504  0.481529   \n",
            "17  0.068908  0.839935  0.020718  0.160575  0.230524  1.063639  0.140891   \n",
            "18  0.020351  0.285243  0.009715  0.351003  0.482716  1.188235  0.556948   \n",
            "19  0.167475  0.519599  0.010373  0.367067  0.169461  1.134177  0.269549   \n",
            "20  0.125989  0.116129  0.009471  0.395275  0.147345  0.561818  0.668976   \n",
            "21  0.237192  0.758993  0.110046  0.253337  0.462160  1.077116  0.236293   \n",
            "22  0.213185  0.284026  0.009629  0.232492  0.207477  0.598431  0.844662   \n",
            "23  0.351363  0.696670  0.010808  0.363033  0.842129  0.604941  0.484409   \n",
            "24  0.248082  0.613803  0.009767  0.230795  0.177714  0.883423  0.196999   \n",
            "25  0.062449  0.492545  0.009203  0.161815  0.215923  0.586277  0.314100   \n",
            "26  0.243010  0.157174  0.009896  0.289531  0.192123  0.494400  0.548197   \n",
            "27  0.146960  1.113222  0.149966  0.244180  0.302741  1.682405  0.135794   \n",
            "28  0.234597  0.765857  0.023223  0.176349  0.332669  0.524062  0.425265   \n",
            "29  0.229896  0.759685  0.137683  0.231894  0.298287  0.860628  0.306756   \n",
            "30  0.222563  0.283322  0.009523  0.195694  0.238426  0.509763  0.310055   \n",
            "31  0.289337  0.425732  0.062026  0.231119  0.189327  0.390396  0.248584   \n",
            "32  0.173711  0.517751  0.009661  0.270806  0.232212  0.577178  0.245010   \n",
            "33  0.113610  0.339233  0.009922  0.331507  0.237880  0.560672  0.452650   \n",
            "34  0.058895  0.348192  0.009993  0.249172  0.492591  0.360932  1.150707   \n",
            "35  0.091772  0.243179  0.009976  0.086412  0.421023  0.353884  0.839874   \n",
            "36  0.058979  0.195900  0.025435  0.183632  0.500022  0.703000  1.001386   \n",
            "37  0.076499  0.489514  0.009589  0.087494  0.693284  0.439291  0.870243   \n",
            "38  0.049396  0.280806  0.009930  0.352487  0.396631  0.622375  0.805871   \n",
            "39  0.021852  0.327341  0.009554  0.349998  0.184704  0.475402  0.435638   \n",
            "40  0.188740  0.599364  0.052869  0.217343  0.230993  0.609192  0.243789   \n",
            "41  0.127418  0.590252  0.009235  0.102876  0.545478  0.565375  0.200278   \n",
            "42  0.113366  0.383932  0.009373  0.235812  0.386502  0.685450  0.279470   \n",
            "43  0.332827  0.112185  0.009083  0.430625  0.516688  0.252724  0.619606   \n",
            "\n",
            "        7         8         9     ...      2038      2039      2040      2041  \\\n",
            "0   0.089424  1.159384  0.160102  ...  0.429072  0.625496  0.000000  0.028738   \n",
            "1   0.225137  1.293093  0.255603  ...  0.329716  0.491991  0.001389  0.030752   \n",
            "2   0.168775  1.651641  0.128448  ...  1.101955  0.954134  0.000000  0.050015   \n",
            "3   0.281948  1.612777  0.092139  ...  0.516484  0.831561  0.000000  0.042724   \n",
            "4   0.014174  1.454706  0.173703  ...  0.639982  0.680834  0.000000  0.026931   \n",
            "5   0.222660  1.651364  0.281036  ...  0.624935  0.810962  0.000273  0.026608   \n",
            "6   0.060558  0.787863  0.035065  ...  0.475862  0.581127  0.001735  0.080256   \n",
            "7   0.154306  0.699194  0.287517  ...  0.213707  0.390934  0.001350  0.020489   \n",
            "8   0.021318  1.441348  0.019459  ...  0.787565  1.216844  0.000000  0.040986   \n",
            "9   0.004826  0.576448  0.395714  ...  0.072600  0.324805  0.000000  0.016452   \n",
            "10  0.126480  1.603154  0.200155  ...  0.582924  0.783417  0.000000  0.046820   \n",
            "11  0.001429  1.359018  0.074817  ...  0.937868  0.863779  0.000000  0.148877   \n",
            "12  0.043730  0.494948  0.006535  ...  0.251719  0.290101  0.000000  0.054797   \n",
            "13  0.282441  1.694195  0.143190  ...  0.567177  0.597709  0.004057  0.091330   \n",
            "14  0.168988  1.561745  0.129924  ...  0.702098  0.682927  0.006942  0.039408   \n",
            "15  0.303569  1.522568  0.275999  ...  0.492627  0.714765  0.000000  0.017572   \n",
            "16  0.067123  1.049297  0.035655  ...  0.334872  0.427006  0.002150  0.052070   \n",
            "17  0.114380  1.598563  0.185862  ...  0.726158  1.109781  0.000000  0.017691   \n",
            "18  0.000000  0.799955  0.091760  ...  0.299749  0.855024  0.000000  0.071969   \n",
            "19  0.000000  1.278908  0.167710  ...  0.385716  0.718561  0.000028  0.054734   \n",
            "20  0.042319  1.228092  0.023649  ...  0.645529  0.718789  0.000280  0.048066   \n",
            "21  0.008218  0.988813  0.305201  ...  0.269207  0.604254  0.000759  0.020478   \n",
            "22  0.004331  1.120301  0.082190  ...  0.450420  0.638858  0.000000  0.116247   \n",
            "23  0.040185  0.600026  0.162321  ...  0.254529  0.261779  0.000000  0.024260   \n",
            "24  0.172254  1.558824  0.152028  ...  0.571869  0.853238  0.002026  0.045774   \n",
            "25  0.021235  1.436881  0.047511  ...  0.866784  0.949037  0.003199  0.042261   \n",
            "26  0.096263  1.461841  0.009518  ...  0.640803  0.605341  0.000000  0.151630   \n",
            "27  0.000976  1.222915  0.414323  ...  0.354603  0.788642  0.000000  0.008614   \n",
            "28  0.014950  1.049880  0.268541  ...  0.435275  0.442943  0.000597  0.101622   \n",
            "29  0.014674  1.322817  0.309625  ...  0.484386  0.644543  0.000000  0.033544   \n",
            "30  0.404445  1.791554  0.186621  ...  0.761778  0.725043  0.000000  0.035977   \n",
            "31  0.239395  1.729483  0.273695  ...  0.705439  0.731713  0.000756  0.079392   \n",
            "32  0.008992  1.417053  0.090574  ...  0.628559  0.759187  0.000000  0.041812   \n",
            "33  0.010440  1.560607  0.158075  ...  0.573039  0.612927  0.000000  0.070852   \n",
            "34  0.000948  0.551472  0.099131  ...  0.194512  0.342601  0.000000  0.039289   \n",
            "35  0.163087  0.570035  0.027402  ...  0.190413  0.451441  0.000000  0.049870   \n",
            "36  0.010691  0.822576  0.080581  ...  0.312263  0.576026  0.000000  0.121079   \n",
            "37  0.027026  0.608957  0.005549  ...  0.359478  0.293076  0.000000  0.047471   \n",
            "38  0.000000  0.875731  0.098676  ...  0.411769  0.528857  0.000000  0.151763   \n",
            "39  0.045408  1.441381  0.197444  ...  0.542049  0.784509  0.000364  0.089393   \n",
            "40  0.116056  1.536955  0.390694  ...  0.668798  0.863485  0.000000  0.037497   \n",
            "41  0.010613  1.028312  0.142433  ...  0.669198  0.854073  0.001970  0.013986   \n",
            "42  0.000000  1.155042  0.093408  ...  0.474959  0.594148  0.000815  0.050612   \n",
            "43  0.052154  0.776249  0.021940  ...  0.292881  0.189234  0.000000  0.021439   \n",
            "\n",
            "        2042      2043      2044      2045      2046      2047  \n",
            "0   0.311349  0.018929  0.064771  0.120665  0.306210  0.146373  \n",
            "1   0.419449  0.037696  0.061523  0.192170  0.281782  0.121434  \n",
            "2   0.565975  0.018447  0.086466  0.128552  0.288342  0.137204  \n",
            "3   0.373547  0.029121  0.069038  0.109102  0.570629  0.204811  \n",
            "4   0.492544  0.025080  0.056281  0.126404  0.587575  0.104614  \n",
            "5   0.507174  0.030005  0.065966  0.207363  0.391000  0.044405  \n",
            "6   0.549018  0.018429  0.119094  0.226565  0.400589  0.191956  \n",
            "7   0.752522  0.022071  0.056836  0.150837  0.129005  0.010702  \n",
            "8   0.629084  0.046837  0.078656  0.218213  0.377144  0.016577  \n",
            "9   0.720270  0.016225  0.061040  0.094701  0.193807  0.025392  \n",
            "10  0.419032  0.031580  0.067308  0.125896  0.665425  0.194076  \n",
            "11  0.557412  0.036563  0.090948  0.187908  0.442508  0.063985  \n",
            "12  0.516473  0.020813  0.092573  0.161824  0.244561  0.179484  \n",
            "13  0.433616  0.036655  0.062451  0.219203  0.641647  0.318797  \n",
            "14  0.509298  0.049064  0.053638  0.285655  0.514895  0.263908  \n",
            "15  0.563918  0.019114  0.054921  0.219092  0.271088  0.033265  \n",
            "16  0.378334  0.017448  0.080158  0.409452  0.218015  0.217771  \n",
            "17  0.510947  0.023314  0.070020  0.183524  0.332749  0.057769  \n",
            "18  0.555898  0.050788  0.071846  0.147096  0.522827  0.071049  \n",
            "19  0.392010  0.062169  0.056350  0.130655  0.907483  0.108026  \n",
            "20  0.643942  0.022796  0.069660  0.231911  0.471616  0.081985  \n",
            "21  0.636139  0.028767  0.063425  0.143588  0.232802  0.006148  \n",
            "22  0.638696  0.016266  0.090604  0.194856  0.371547  0.137911  \n",
            "23  0.724609  0.014269  0.060378  0.102884  0.230300  0.010930  \n",
            "24  0.408368  0.051482  0.061383  0.206498  0.683448  0.068535  \n",
            "25  0.440553  0.031917  0.065982  0.248267  0.293154  0.091634  \n",
            "26  0.578414  0.024900  0.069718  0.171603  0.441142  0.097671  \n",
            "27  0.484681  0.017864  0.070087  0.102106  0.603171  0.007633  \n",
            "28  0.559915  0.030209  0.067814  0.145332  0.253200  0.118032  \n",
            "29  0.427736  0.014647  0.063055  0.119592  0.552101  0.151783  \n",
            "30  0.475976  0.016153  0.062570  0.153502  0.291724  0.117462  \n",
            "31  0.501134  0.026180  0.075386  0.173181  0.300895  0.180001  \n",
            "32  0.459810  0.019620  0.063339  0.137838  0.340440  0.078618  \n",
            "33  0.518022  0.014130  0.054532  0.108850  0.427715  0.165604  \n",
            "34  0.616258  0.019145  0.090097  0.116515  0.242933  0.178564  \n",
            "35  0.593625  0.021186  0.080776  0.126992  0.216136  0.085310  \n",
            "36  0.663711  0.015604  0.061714  0.098663  0.255773  0.219138  \n",
            "37  0.472892  0.015548  0.067735  0.106743  0.200771  0.219952  \n",
            "38  0.688622  0.022122  0.066350  0.133469  0.285684  0.129616  \n",
            "39  0.637655  0.026289  0.063916  0.164726  0.449807  0.087991  \n",
            "40  0.468436  0.018293  0.058145  0.159116  0.459807  0.117767  \n",
            "41  0.426744  0.018634  0.066282  0.120566  0.149968  0.074987  \n",
            "42  0.409054  0.018269  0.070947  0.115577  0.284195  0.193456  \n",
            "43  0.478284  0.051357  0.073095  0.174488  0.220358  0.170455  \n",
            "\n",
            "[44 rows x 2048 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LkV2N-gdjZXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}